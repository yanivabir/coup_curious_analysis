```{r setup, echo = F}
knitr::opts_chunk$set(echo = FALSE)
# Load libraries
library(data.table)
setDTthreads(11)
library(ggplot2)
library(ggrain)
library(cowplot)
theme_set(theme_minimal()  +
            theme_cowplot(14, font_family = "Helvetica", rel_small = 0.8) + 
            theme(legend.position = "none",
                  strip.text = element_text(size = 9),
                  plot.margin = margin(1.5,2,1.5,2)))


sampleName <- "v1.01"

source("load_data_and_exclude.R")
list[wait, rating_clps, know_test, 
     prob_judge, quest, quality] = load_exclude(sampleName)

source("compute_ID.R")
list[naive_ID, alphas] <- computeNaive(quest)

# Coup relevance key
coup_rel_key <- fread(file.path("..", "data", "coup_rel_key.csv"))

# Function to compute standard errors
se <- function(x) sd(x, na.rm = T) / sqrt(sum(!is.na(x)))

# Colors, lines labels
block_colors <- c("#cc1337", "#005b8d")
block_labels <- c("Coup-related", "General")
levs <- c("coup", "general")
block_lines <- c("solid", "dashed")

```

## Waiting task averages

```{r waiting_grand_avg_proportions}
sz = 0.8 # Scatter point size for plots

## Summarize waiting task by participant and block
wait_sum <- wait[!is.na(choice), .(wait = mean(choice == "wait"),
                                   skip = mean(choice == "skip"),
                                   know = mean(choice == "know")), 
                 by = .(PID, block)]

# Transform wide to long
wait_sum <- melt(wait_sum, id.vars = c("PID", "block"))

# Pretty labels for wait, skip know
wait_sum[, variable := factor(variable, labels = c("Wait", "Skip", "Know"))]

# Pretty labels for block
wait_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

# Summarize by block and respose
wait_sum_sum <- wait_sum[, .(value = mean(value)), 
                         by = .(block, variable)]

# Plot waiting task by participant
p_wait_mean_p <- ggplot(wait_sum, aes(x = variable, y = value, 
                                    color = block)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.2),
             size = sz, alpha = 0.2) +
    geom_crossbar(data = wait_sum_sum, aes(ymin = value, ymax = value),
             position = position_dodge(width = 0.5), width = 0.4) +
  scale_color_manual(values=block_colors) +
  labs(x = "Choice",
       y = "Proportion",
       color = 'Question type',
       title = "Proportion waited\nby each participant")

## Summarize waiting task by question
wait_sum <- wait[, .(wait = mean(choice == "wait"),
                     skip = mean(choice == "skip"),
                     know = mean(choice == "know")), by = c("questionId", "block")]

# Transform wide to long
wait_sum <- melt(wait_sum, id.vars = c("questionId", "block"))

# Pretty labels for response
wait_sum[, variable := factor(variable, labels = c("Wait", "Skip", "Know"))]

# Pretty labels of question type
wait_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

# Summarize by type and response
wait_sum_sum <- wait_sum[, .(value = mean(value)), by = c("block", "variable")]


# Plot waiting task by question
p_wait_mean_q <- ggplot(wait_sum, aes(x = variable, y = value, 
                                    color = block)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.1),
             size = sz, alpha = 0.2) +
    geom_crossbar(data = wait_sum_sum, aes(ymin = value, ymax = value),
             position = position_dodge(width = 0.5), width = 0.4) +
  scale_color_manual(values=block_colors) +
  labs(x = "Choice",
       y = "Proportion",
       color = 'Question type',
       title = "Proportion Waited\nfor Each Question")

l <- get_legend(p_wait_mean_p + theme(legend.position = "top", 
                                      legend.justification = NULL))

(p_wait_mean <- plot_grid(l,
                         plot_grid(p_wait_mean_p, p_wait_mean_q),
                         ncol = 1,
                         rel_heights = c(.1, 1)))
```

Fig. 1. Response proportions by question type. Left panel displays proportions summarized by participant. We observe the expected considerable individual differences. We also observe a high proportion of 'Know' responses. There is a slight tendency to wait more for general questions, and respond 'Know' more often to coup-related questions. Skipping proportions are similar. On the right the data is summarized by question. The trends are similar summarized this way.

## Question rating averages
```{r rating_grand_avg, warning=FALSE}
# Summarize rating task by participant
rate_sum <- melt(rating_clps[, -c("questionId", "sess")], id.vars = c("PID", "block"))

rate_sum <- rate_sum[, .(value = mean(value)), 
                     by = c("PID", "block", "variable")]


rate_sum[, variable := factor(variable, 
                              levels = c("useful", "confidence", 
                                         "affect", "congruence"),
                              labels = c("Usefulness", "Confidence", "Affect",
                                         "Belief-\ncongruence"))]

rate_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

rate_sum_sum <- rate_sum[, .(value = mean(value)), by = c("block", "variable")]


# Plot rating task
p_rate_mean_p <- ggplot(rate_sum, aes(x = variable, y = value, 
                                    color = block)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.2),
             size = sz, alpha = 0.2) +
  geom_crossbar(data = rate_sum_sum, aes(ymin = value, ymax = value),
             position = position_dodge(width = 0.5), width = 0.5) +
    scale_color_manual(values=block_colors) +
  labs(x = "Scale",
       y = "Average rating",
       color = 'Question type',
       title = "Average Rating for Participants") 

# Summarize rating task by question
rate_sum <- melt(rating_clps[, -c("PID", "sess")], 
                 id.vars = c("questionId", "block"))

rate_sum <- rate_sum[, .(value = mean(value)), 
                     by = c("questionId", "block", "variable")]

rate_sum[, variable := factor(variable, 
                              levels = c("useful", "confidence", 
                                         "affect", "congruence"),
                              labels = c("Usefulness", "Confidence", "Affect",
                                         "Belief-\ncongruence"))]

rate_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

rate_sum_sum <- rate_sum[, .(value = mean(value)), by = c("block", "variable")]


# Plot rating task
p_rate_mean_q <- ggplot(rate_sum, aes(x = variable, y = value, 
                                    color = block)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.1),
             size = sz, alpha = 0.2) +
  geom_crossbar(data = rate_sum_sum, aes(ymin = value, ymax = value),
             position = position_dodge(width = 0.5), width = 0.5) +
    scale_color_manual(values=block_colors) +
  labs(x = "Scale",
       y = "Average rating",
       color = 'Question type',
       title = "Average Rating for Questions")

l <- get_legend(p_rate_mean_q + theme(legend.position = "top", 
                                      legend.justification = NULL))

p_rate_mean <- plot_grid(l,
                         plot_grid(p_rate_mean_p, p_rate_mean_q),
                         ncol = 1,
                         rel_heights = c(.1, 1))
suppressWarnings(print(p_rate_mean))

```

Fig. 2. Rating covariates by question type. Left panel summarizes ratings by participant, right panel summarizes them by question. For both we see that coup-releated questions elicit higher ratings of confidence and usefulness relative to general questions. Answers to general questions are expected to elicit more positive affect. We see relatively little variance in response to the belief congruence probe when summarized by question, and a lot of individual differences in belief congurence ratings, indicating that participants are not consistent in their ratings.

## Rating - waiting correlations
```{r rating_waiting, warning=FALSE}
# Summarize rating task by question
rate_sum <- rating_clps[, .(confidence = mean(confidence),
                            affect = mean(affect),
                            congruence = mean(congruence),
                            useful= mean(useful)), 
                     by = c("questionId", "block")]


rate_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

## Summarize waiting task by question
wait_sum <- wait[, .(wait = mean(choice == "wait"),
                     skip = mean(choice == "skip"),
                     know = mean(choice == "know")), by = c("questionId", "block")]

# Pretty labels of question type
wait_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]

wait_rate <- merge(wait_sum, rate_sum, by = c("questionId", "block"))

# wide to long
wait_rate <-  melt(wait_rate, measure.vars = c("wait", "skip", "know"),
                   variable.name = "choice", value.name = "prop")

wait_rate <-  melt(wait_rate, 
                   measure.vars = c("confidence", "affect", "congruence", "useful"),
                   variable.name = "probe", value.name = "rating")

wait_rate[, probe := factor(probe, 
                              levels = c("useful", "confidence", 
                                         "affect", "congruence"),
                              labels = c("Usefulness", "Confidence", "Affect",
                                         "Belief congruence"))]

# Pretty labels for choice
wait_rate[, choice := factor(choice, labels = c("Wait", "Skip", "Know"))]


ggplot(wait_rate, aes(x = rating, y = prop, color = choice)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method="glm", se=F, formula=y~x) +
  facet_wrap("probe", scales = "free", switch = "x") +
  theme(legend.position = "top",
        strip.background = element_blank(),
        strip.placement = "outside",
        strip.text = element_text(size = 14)) +
  labs(x = "",
       y = "Proprtion",
       color = "Choice")
```

Fig. 3. Relationship between waiting-task responses and covariate ratings. Each question is represented by three points, denoting the respective proportion of 'Know', 'Wait', and 'Skip' choices. Both waiting and 'Know' responses increase with usefulness. There is a strong association between rated confidence and the proportion of 'Know' responses. As the predicted affect for the answer becomes more positive, waiting and 'Know' responses increase. Belief congruence is associated with a larger proportion of 'Know' responses. All trend lines are logistic regression, which cannot capture non-monotonicity.

## Event-probability judgments - averages and histograms

```{r prob_judge_grand_avg}
# Summarize porbability judgement by participant
prob_sum <- prob_judge[, .(response = mean(response),
                           se = se(response)),
                       by = .(PID, block)]
  

prob_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]


# Plot rating task
p_prob_mean_p <- ggplot(prob_sum, aes(x = block, y = response, 
                                    color = block)) +
  geom_rain(alpha = .3) +
  scale_color_manual(values=block_colors) +
  labs(x = "Question type",
       y = "Average probability judgment",
       title = "Average Probability Judgment\nfor Participants") 

# Summarize rating task by item
prob_sum <- prob_judge[, .(response = mean(response),
                           se = se(response)),
                       by = .(itemId, block)]
  

prob_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]


# Plot rating task
p_prob_mean_q <- ggplot(prob_sum, aes(x = block, y = response, 
                                    color = block)) +
  geom_rain(alpha = .3) +
  scale_color_manual(values=block_colors) +
  labs(x = "Question type",
       y = "Average probability judgment",
       title = "Average Probability Judgment\nfor Items")


(p_prob_mean <- plot_grid(p_prob_mean_p, p_prob_mean_q))
```

Fig. 4. We see considerable individual differences in event probability judgments. Across participants (left panel), the distribution seems bi modal, with a peak just below and just above 0.5. The distribution of average probability rating summarized by items indicates good psychometric qualities: most items cluster between 0.4 and 0.6, giving us maximum dynamic range to meaures individual differences. We also have a few items at the extreme helping with calibrating particiapnts' responses.

```{r prob_judge_per_item}
ggplot(prob_judge, aes(x = response, fill = block)) +
  geom_histogram(binwidth = 0.03) +
  facet_wrap("short_desc", labeller = label_wrap_gen()) +
  theme(strip.background = element_blank(),
        strip.text = element_text(size = 6)) +
  labs(x = "Probability judgment",
         y = "# participants",
         title = "Histogram of Probability Judgments per Item") +
  scale_x_continuous(breaks = c(0.0, 0.5, 1.0))
```

Fig. 5. Histograms of probability judgment per item. Note that while some items elicit quite uniform responses (the probability of Israel and Saudi Arabia signing a peace deal), others are clustered around 0.5 (Madrid flight cheaper than Paris flight on a specific date). The last two items in each category are meant to elicit 0 and 1 responses resepectively. It seems that people are likelier to give extreme responses close to 1 than to 0.

## Knowledge test averages

```{r know_test_grand_avg}
# Summarize knowledge test by participant
know_sum <- know_test[, .(correct = mean(correct)),
                       by = .(PID, block)]
  

know_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]


# Plot knowledge test
p_know_mean_p <- ggplot(know_sum, aes(x = block, y = correct, 
                                    color = block)) +
  geom_rain(alpha = .3) +
  scale_color_manual(values=block_colors) +
  labs(x = "Question type",
       y = "Proportion correct",
       title = "Knowledge Test\nby Participant") 

# Add date to date
know_sum <- merge(know_sum, quality[, .(PID, date)], 
                  by = "PID", all.x = T)

# Summarize by date
know_sum_date <- know_sum[, .(correct = mean(correct),
                              se = se(correct)), by = c("date", "block")]

# Plot knowledge test by date
p_know_mean_d <- ggplot(know_sum_date, aes(x = date, y = correct, 
                                    color = block)) +
  geom_pointrange(aes(ymin = correct - se, ymax = correct + se)) +
  scale_color_manual(values=block_colors) +
  theme(legend.position = "top") +
  labs(x = "Date",
       y = "Proportion correct",
       color = "Question type",
       title = "Knowledge Test by Date") 


# Summarize knowledge test by item
know_sum <- know_test[, .(correct = mean(correct)),
                       by = .(probe, block)]
  

know_sum[, block := factor(block,
                          levels = levs,
                          labels = block_labels)]


# Plot knowledge test
p_know_mean_q <- ggplot(know_sum, aes(x = block, y = correct, 
                                    color = block)) +
  geom_rain(alpha = .3) +
  scale_color_manual(values=block_colors) +
  labs(x = "Question type",
       y = "Proportion correct",
       title = "Knowledge Test \nby Item")


(p_know_mean <- plot_grid(p_know_mean_p, p_know_mean_q))

p_know_mean_d
```

## Coup relevance - subscales and individual items

```{r coup_relevance_scatter, warning=FALSE}
# Coup relevance data.table
coup_rel <- quest[, grepl("coup|PID", names(quest)), with = F]

# Add date
coup_rel <- merge(coup_rel, quality[!is.na(date), .(PID, date)], 
                  by = "PID", all.x = T)

# Wide to long
coup_rel_l <- melt(coup_rel, id.vars = c("PID", "date"))

# Split to relevance and attitude
coup_rel_l[, item_n := as.numeric(strsplit(as.character(variable), "_")[[1]][3]), 
           by = .(variable)]
coup_rel_l[, scale := ifelse((item_n < 8) | (item_n == 22), "Relevance", "Attitude")]

coup_rel_sum <- coup_rel_l[, .(value = mean(value + 1, na.rm = T)), by = .(PID, date, scale)]
coup_rel_sum_w <- dcast(coup_rel_sum, PID + date ~ scale)

ggplot(coup_rel_sum_w, aes(x = Relevance, y = Attitude)) +
  geom_point(alpha = 0.1) +
  geom_density2d() +
  coord_fixed() +
  scale_x_continuous(breaks = 1:5,
    labels = c("1\nDon't care", "2", "3", "4", "5\nCare"),
    limits = c(0.9, 5.1)) +
  scale_y_continuous(breaks = 1:5,
    labels = c("Support 1", "2", "3", "4", "Oppose 5"),
    limits = c(0.9, 5.1)) +
  labs(title = "Subscales of Coup-Relevance Questionnaire")

ggplot(coup_rel_sum_w, aes(x = Relevance, y = Attitude)) +
  geom_point(alpha = 0.1) +
  geom_density2d() +
  coord_fixed() +
  facet_wrap("date") +
  scale_x_continuous(breaks = 1:5,
    labels = c("1\nDon't care", "2", "3", "4", "5\nCare"),
    limits = c(0.9, 5.1)) +
  scale_y_continuous(breaks = 1:5,
    labels = c("Support 1", "2", "3", "4", "Oppose 5"),
    limits = c(0.9, 5.1)) +
  labs(title = "Subscales of Coup-Relevance Questionnaire by Date")

coup_rel_date_sum <- coup_rel_l[, .(value = mean(value, na.rm = T),
                                    se = se(value)), by = c("date", "scale")]

ggplot(coup_rel_date_sum, aes(x = date, y = value, color = scale)) + 
  geom_pointrange(aes(ymin = value - se, ymax = value + se)) +
  labs(x = "Date", y = "Average rating", color = "Scale",
       title = "") +
  theme(legend.position = "top")
```


```{r coup_rel_items, warning=FALSE}
coup_rel_key[grepl("negative|for", coding), short_desc := paste0("¬", short_desc)]

coup_rel_l <- merge(coup_rel_l, coup_rel_key[, .(itemId, short_desc)],
                  by.y = "itemId", by.x = "variable")

coup_rel_l[, short_desc := factor(short_desc,
                                  levels = coup_rel_key$short_desc)]


ggplot(coup_rel_l, aes(x = value, fill = scale)) +
  geom_histogram(binwidth = 1) +
  facet_wrap("short_desc", labeller = label_wrap_gen()) +
  theme(strip.background = element_blank(),
        strip.text = element_text(size = 6)) +
  labs(x = "Rating",
         y = "# participants",
         title = "Histogram for Each Coup Relevance Item")

```

```{r ideology, fig.dim=c(8,8), message=FALSE, warning=FALSE}
ideo <- quest[, grep("PID|iwin|socialism|secular|left", 
                     colnames(quest)), with = F]

corrplot::corrplot(cor(ideo[, .(IWIN1 = iwin_1, IWIN2 = iwin_2, IWIN3 = iwin_3, 
                      `Left-right` = left_right, 
                                  `Secular-religious` = secular_religious, 
                                  `Socialism-capitalism` = socialism_capitalism)], use = "pairwise.complete.obs"), 
         method = "ellipse")

ideo[, iwin := rowMeans(.SD[, .(iwin_1, iwin_2, iwin_3)]) + 1]

ideo_coup_rel <- merge(ideo, coup_rel_sum_w, by = "PID")

ideo_coup_rel[, left_right := left_right + 1]
ideo_coup_rel[, secular_religious := secular_religious + 1]
ideo_coup_rel[, socialism_capitalism := socialism_capitalism + 1]

GGally::ggpairs(ideo_coup_rel[, .(IWIN = iwin, `Left-right` = left_right, 
                                  `Secular-religious` = secular_religious, 
                                  `Socialism-capitalism` = socialism_capitalism, 
                                  `Coup relevance` = Relevance, 
                                  `Coup attitude` = Attitude)],
                lower = list(continuous = "density"),
                progress = F,
                title = "Coup Relevance and Ideology Measures")
```

```{r affect_motivation_quests}
ctrl_quests <- quest[, grep("PID|stai|reg_Q|gallup|apathy", 
                     colnames(quest)), with = F]

corrplot::corrplot(cor(ctrl_quests[, -c("PID"), with = F],
                       use = "pairwise.complete.obs"),
                   method = "square", tl.cex = 0.5) 

```
```{r wait_skip_affect_motivation_choice}
# Function to summarise data and merge with ID measure
merge_w_ID <- function(resp_sum, ID, id, label){
  # Bin ID measures
  thisID <- ID[!is.na(get(id))]
  thisID[, bin_n := factor(dplyr::ntile(get(id), 6))]
  thisID[, bin := mean(get(id)), by = bin_n]

  # Merge
  id_resp <- merge(resp_sum, thisID[, .(PID, bin)], by = "PID")

  # Average
  id_resp_sum <- id_resp[, .(resp = mean(resp),
                                         se = sd(resp) / sqrt(.N)), 
                                     by = c("bin", "block")]
  
  # Label
  id_resp_sum$measure <- label
  
  return(id_resp_sum)
}

plot_against_ID <- function(resp_sum, label){
  # Pretty labels of question type
  resp_sum[, block := factor(block,
                             levels = levs,
                             labels = block_labels)]
  
  # Make plot for each measure
  measures <- c("coup_relevance", "coup_attitude", "affect", "motivation")
  
  id_resp_pl <- lapply(measures, function(x) {
    dat <- merge_w_ID(resp_sum, naive_ID, paste0("naive_", x), x)
    return(ggplot(dat[!is.na(resp)], aes(x = bin, y = resp, color = block)) +
             geom_pointrange(aes(ymin = resp - se, ymax = resp + se)) +
             scale_color_manual(values=block_colors) +
             labs(x = str_to_sentence(gsub("_", " ", x)),
                  y = label,
                  color = "Question type") +
             theme(plot.margin = margin(10,10,2,3)))
  })
  
  # Fix y range to be the same for all
  ranges <- sapply(id_resp_pl, function(p) layer_scales(p)$y$range$range)
  id_resp_pl <- lapply(id_resp_pl, function(p) p + ylim(min(ranges), max(ranges)))
  
  # Plot in grid
  return(plot_grid(plotlist = id_resp_pl,
                   nrow = 2))
}

## Summarize wait vs. skip by participant
wait_sum <- wait[choice %in% c("skip", "wait"), 
                 .(resp = mean(choice == "wait")), by = c("PID", "block")]
plot_against_ID(wait_sum, "Prop. waited")

## Summarize known vs. rest by participant
wait_sum <- wait[choice %in% c("skip", "know"),  
                 .(resp = mean(choice == "know")), by = c("PID", "block")]
plot_against_ID(wait_sum, "Prop. known")

## Summarize satisfaction
satis_sum <- wait[!is.na(wait_satisfaction), 
                  .(resp = mean(wait_satisfaction) + 1),
                  by = c("PID", "block")]
plot_against_ID(satis_sum, "Satisfaction")

## Summarize usefulness ratings
useful_sum <- rating_clps[, 
                  .(resp = mean(useful)),
                  by = c("PID", "block")]
plot_against_ID(useful_sum, "Usefulness")

## Summarize affect ratings
affect_sum <- rating_clps[, 
                  .(resp = mean(affect)),
                  by = c("PID", "block")]
plot_against_ID(affect_sum, "Question affect")

## Summarize confidence ratings
conf_sum <- rating_clps[, 
                  .(resp = mean(confidence)),
                  by = c("PID", "block")]
plot_against_ID(conf_sum, "Confidence")

## Summarize congruence ratings
cong_sum <- rating_clps[, 
                  .(resp = mean(congruence)),
                  by = c("PID", "block")]
plot_against_ID(cong_sum, "Belief Congruence")

```
```{r ID_measures_by_date}
# Merge dates into data.table
ID_by_date <- merge(naive_ID, quality[, .(PID, date)], by = "PID", all.x = T)

# Wide to long
ID_by_date <- melt(ID_by_date, id.vars = c("PID", "date"),
                   measure.vars = c("naive_coup_relevance", 
                                    "naive_coup_attitude",
                                    "naive_affect",
                                    "naive_motivation"))

# Summarise by date
ID_by_date <- ID_by_date[, .(value = mean(value, na.rm =T),
                             se = se(value)), by = c("date", "variable")]

ID_by_date[, coup_related := grepl("coup", variable)]
ID_by_date[, variable := factor(variable, levels = levels(variable),
    labels = str_to_sentence(gsub("naive ", "", 
                                  gsub("_", " ", levels(variable)))))]

ggplot(ID_by_date, aes(x = date, y = value, color = variable)) +
  geom_pointrange(aes(ymin = value - se, ymax = value + se)) +
  theme(legend.position = "top", panel.spacing = unit(30, "points"),
        strip.background = element_blank(),
        strip.text = element_blank()) +
  facet_wrap("coup_related") +
  labs(x = "Date",
       y = "Average value (std.)",
       color = "Measure")
```

```{r knowledge_know}
know_test_sum <- know_test[, .(correct = mean(correct)), by = .(PID, block)]

know_v_skip <- wait[choice %in% c("know", "skip"), .(know_v_skip = mean(choice == "know")), by = .(PID, block)]

know_prop <- wait[, .(know_prop = mean(choice == "know")), by = .(PID, block)]

wait_v_skip <- wait[choice %in% c("wait", "skip"), .(waited = mean(choice == "wait")), by = .(PID, block)]

know_sum <- merge(know_test_sum, know_v_skip, by = c("PID", "block"), all = T)
know_sum <- merge(know_sum, know_prop, by = c("PID", "block"), all = T)
know_sum <- merge(know_sum, wait_v_skip, by = c("PID", "block"), all = T)

know_sum_l <- melt(know_sum, id.vars = c("PID", "block", "correct"))

know_sum_l[, block := factor(block, levels = levs, labels = block_labels)]

ggplot(know_sum_l, aes(x = correct, y = value, color = block)) +
  geom_density_2d() +
  scale_color_manual(values=block_colors) +
  geom_smooth(formula=y~x, se=F, method="lm") +
  facet_grid(variable ~ block) +
  theme(legend.position = "top") +
  labs(x = "Test prop. correct",
       y = "",
       color = "Question type")

print(know_sum_l[, .(r = cor(correct, value, use = "complete.obs")), by = c("block", "variable")])
```

